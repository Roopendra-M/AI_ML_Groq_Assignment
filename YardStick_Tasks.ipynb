{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UBwsgZqQMd_"
      },
      "source": [
        "### =================================================\n",
        "# AI/ML Internship Assignment with Groq Api\n",
        "## Tasks\n",
        "### 1. Conversation Management and Summarization\n",
        "### 2. JSON Schema classification and Extraction\n",
        "### ================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: openai in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (1.107.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (4.2.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from openai) (0.24.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->openai) (0.17.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\programdata\\anaconda3\\lib\\site-packages (from httpcore<0.18.0,>=0.15.0->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Hf1A0mYOQZRV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "import requests\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ut3Z_bCQnkr"
      },
      "source": [
        "## Setup API key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-icBe95vQtYq"
      },
      "outputs": [],
      "source": [
        "os.environ[\"GROQ_API_KEY\"]=\"YOUR_GROQ_API_KEY\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9yJ9JnDxRBw_"
      },
      "outputs": [],
      "source": [
        "client=OpenAI(\n",
        "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
        "    base_url=\"https://api.groq.com/openai/v1\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Dg9V3YPRRut"
      },
      "source": [
        "### Task-1 Conversation Management with Summarization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VQZjQdJkRZJn"
      },
      "outputs": [],
      "source": [
        "class ConversationManager:\n",
        "    def __init__(self, model=\"openai/gpt-oss-20b\", k=3):\n",
        "        self.model = model\n",
        "        self.k = k\n",
        "        self.history = []\n",
        "        self.run_count = 0\n",
        "\n",
        "    def add_message(self, role, content):\n",
        "        self.history.append({\"role\": role, \"content\": content})\n",
        "        self.run_count += 1\n",
        "\n",
        "        # Summarize every k runs\n",
        "        if self.run_count % self.k == 0:\n",
        "            self.summarize()\n",
        "\n",
        "    def summarize(self):\n",
        "        response = client.chat.completions.create(\n",
        "            model=self.model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"Summarize this conversation briefly.\"},\n",
        "                {\"role\": \"user\", \"content\": str(self.history)}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        summary = response.choices[0].message.content\n",
        "        # Replace history with summary\n",
        "        self.history = [{\"role\": \"system\", \"content\": f\"Summary: {summary}\"}]\n",
        "\n",
        "    def get_truncated_history(self, limit=3, by=\"turns\"):\n",
        "        # Truncate conversation by turns or characters\n",
        "        if by == \"turns\":\n",
        "            return self.history[-limit:]\n",
        "        elif by == \"chars\":\n",
        "            return [{\"role\": m[\"role\"], \"content\": m[\"content\"][:limit]} for m in self.history]\n",
        "        else:\n",
        "            return self.history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTDWKVLzUT0O"
      },
      "source": [
        "### Demo task 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjtF29WiUWUF",
        "outputId": "60157f8b-bdd1-4d19-e2a9-d38d00dea1f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===Conversation after 3 turns with summarization===\n",
            "[{'role': 'system', 'content': 'Summary: **Conversation summary:**\\n\\n1. The user says they want to learn about AI.  \\n2. The assistant briefly explains that AI stands for Artificial Intelligence.  \\n3. The user then asks for more information about machine learning.'}]\n",
            "[{'role': 'system', 'content': 'Summary: **Conversation summary:**\\n\\n1. The user says they want to learn about AI.  \\n2. The assistant briefly explains that AI stands for Artificial Intelligence.  \\n3. The user then asks for more information about machine learning.'}, {'role': 'assiastant', 'content': 'Machine Learning is the subset of AI.'}, {'role': 'user', 'content': 'What is Deep Learning'}]\n"
          ]
        }
      ],
      "source": [
        "conv=ConversationManager(k=3)\n",
        "# simulate conversation\n",
        "conv.add_message(\"user\",\"Hi i want to learn AI.\")\n",
        "conv.add_message(\"Assistant\",\"Sure! AI means Artificial Intelligence.\")\n",
        "conv.add_message(\"user\",\"Can you tell me about Machine learning?\")\n",
        "\n",
        "# summarization should trigger here\n",
        "\n",
        "print(\"===Conversation after 3 turns with summarization===\")\n",
        "print(conv.history)\n",
        "\n",
        "conv.add_message(\"assiastant\",\"Machine Learning is the subset of AI.\")\n",
        "conv.add_message(\"user\",\"What is Deep Learning\")\n",
        "\n",
        "print(conv.history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Su6Jt-MjWuyU",
        "outputId": "54f630a6-7069-4068-b423-b370a36a3397"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Truncated History (last 2 turns) ===\n",
            "[{'role': 'assiastant', 'content': 'Machine Learning is the subset of AI.'}, {'role': 'user', 'content': 'What is Deep Learning'}]\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n=== Truncated History (last 2 turns) ===\")\n",
        "print(conv.get_truncated_history(limit=2, by=\"turns\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeA5e6KLWxmV",
        "outputId": "35f85ed2-e9ab-40d7-b750-2b909bed8ab4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Truncated by Characters (first 20 chars each) ===\n",
            "[{'role': 'system', 'content': 'Summary: **Conversat'}, {'role': 'assiastant', 'content': 'Machine Learning is '}, {'role': 'user', 'content': 'What is Deep Learnin'}]\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n=== Truncated by Characters (first 20 chars each) ===\")\n",
        "print(conv.get_truncated_history(limit=20, by=\"chars\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRgAl04Dq24L",
        "outputId": "ba13edfa-3630-4a71-a304-7ded95b10ae4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Truncated History (last 2 turns) ===\n",
            "[{'role': 'system', 'content': 'Summary: **Conversation summary:**\\n\\n1. The user says they want to learn about AI.  \\n2. The assistant briefly explains that AI stands for Artificial Intelligence.  \\n3. The user then asks for more information about machine learning.'}, {'role': 'assiastant', 'content': 'Machine Learning is the subset of AI.'}, {'role': 'user', 'content': 'What is Deep Learning'}]\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n=== Truncated History (last 2 turns) ===\")\n",
        "print(conv.get_truncated_history(limit=2, by=\"\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4UDzQGRW6eK"
      },
      "source": [
        "### Task 2..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VvNphofKW9s3"
      },
      "outputs": [],
      "source": [
        "user_schema = {\n",
        "    \"name\":\"Extract_user_info\",\n",
        "    \"description\":\"Extract user details from a chat\",\n",
        "    \"parameters\":{\n",
        "        \"type\":\"object\",\n",
        "        \"properties\":{\n",
        "            \"name\":{\n",
        "                \"type\":\"string\",\n",
        "                \"description\":\"The name of the user\"\n",
        "            },\n",
        "            \"email\":{\n",
        "                \"type\":\"string\",\n",
        "                \"description\":\"The email of the user\"\n",
        "            },\n",
        "            \"phone\":{\n",
        "                \"type\":\"string\",\n",
        "                \"description\":\"The phone number of the user\"\n",
        "            },\n",
        "            \"location\":{\n",
        "                \"type\":\"string\",\n",
        "                \"description\":\"The location of the user\"\n",
        "            },\n",
        "            \"age\":{\n",
        "                \"type\":\"integer\",\n",
        "                \"description\":\"The age of the user\"\n",
        "            }\n",
        "        },\n",
        "        \"required\":[\"name\",\"email\",\"phone\",\"location\",\"age\"]\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CAkmAE2jX2lg"
      },
      "outputs": [],
      "source": [
        "def extract_info(chat_text):\n",
        "  response = client.chat.completions.create(\n",
        "      model=\"openai/gpt-oss-20b\",\n",
        "      messages=[\n",
        "          {\"role\":\"system\",\"content\":\"Extract user details into JSON\"},\n",
        "          {\"role\":\"user\",\"content\":chat_text}\n",
        "      ],\n",
        "      functions=[user_schema],\n",
        "      function_call={\"name\":\"Extract_user_info\"}\n",
        "  )\n",
        "  return json.loads(response.choices[0].message.function_call.arguments)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naAn_qtUY0VY"
      },
      "source": [
        "### Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_h542NfY2TT",
        "outputId": "840c9d27-5a37-4918-c12e-3a63ee915a96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "====JSON Extraction Results ====\n",
            "{'age': 21, 'email': 'mardalaroopendra@gmail.com', 'location': 'Bangalore', 'name': 'Roopendra', 'phone': '8519804772'}\n",
            "{'age': 30, 'email': 'kavita@gmail.com', 'location': 'Delhi', 'name': 'Kavitha', 'phone': '9123456789'}\n",
            "{'age': 27, 'email': '', 'location': 'Mumbai', 'name': 'charan', 'phone': '9988776655'}\n"
          ]
        }
      ],
      "source": [
        "samples = [\n",
        "    \"Hi, I'm Roopendra and i am 21 year old currently working in Bangalore and my mobile number is 8519804772 an my mail id is mardalaroopendra@gmail.com\",\n",
        "    \"Hello, this is kavitha from Delhi. I'm 30 years old. You can reach me at kavita@gmail.com or 9123456789.\",\n",
        "    \"My name is charan, 27 years old, based in Mumbai.  9988776655.\"\n",
        "]\n",
        "\n",
        "print(\"====JSON Extraction Results ====\")\n",
        "for s in samples:\n",
        "  print(extract_info(s))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
